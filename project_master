

# ## - Importiamo le librerie che servono per fare Web Scraping da giallo zafferano

import requests 
import bs4
import csv
from tqdm import tqdm_notebook as tqdm
import pprint

! pip install --user pyqrcode
! pip install --user --upgrade pip
import pyqrcode
from pyqrcode import QRCode


num = 1
webpage = f"https://www.giallozafferano.it/ricette-cat/page{num}/Antipasti/"
response = requests.get(webpage, verify=False)
print("Status: " + str(response.status_code))
doc = bs4.BeautifulSoup(response.text)


def parse_antipasti(antipasto):
    titolo = antipasto.find('h2', class_ = "gz-title").text
    link = antipasto.find('h2', class_ = "gz-title").find("a")["href"]
    qrcodeurl = pyqrcode.create(link)
    qrcodeurl.svg(f"/home/master/Desktop/qrcode_antipasti/qrcode-{titolo}.svg", scale=8)
    filename = f"/home/master/Desktop/qrcode_antipasti/qrcode-{titolo}.svg"
    descrizione =  antipasto.find('div', class_ = "gz-description").text
    return {'titolo' : titolo, 'link' : link, 'descrizione' : descrizione , 'qrcode' : filename}


antipasti_list= []
for num in tqdm(range(1,101)):
    webpage = f"https://www.giallozafferano.it/ricette-cat/page{num}/Antipasti/"
    response = requests.get(webpage,  verify=False)
    doc = bs4.BeautifulSoup(response.text)
    lista = doc.findAll('div', class_ = "gz-content-recipe-horizontal")
    for antipasto in lista:
        try:
            antipasti_list.append(parse_antipasti(antipasto))
        except:
            pass
        

# creazione dataframe

import pandas as pd
import numpy as np
ds_antipasti = pd.DataFrame(antipasti_list)
ds_antipasti['id_a'] = range(1, len(antipasti_list)+1)
ds_antipasti.head()

# ## dettagli

dettagli = []

for item in tqdm(ds_antipasti.iterrows(), total=ds_antipasti.shape[0]):
    try:
        id_a = item[1][3]
        link = item[1][1]
        resp = requests.get(link, verify = False)
        parse = bs4.BeautifulSoup(resp.text)
        rate = parse.find('div', class_='rating_panel')['data-content-rate']
        n_voti = parse.find('div', class_="rating_rate")["title"]
        n_commenti = parse.find('div', class_='gz-pTop4x').text.replace("\n","")
        details = parse.findAll('span', class_ = 'gz-name-featured-data')
        difficolta = details[0].text.split(":")[1]
        preparazione = details[1].text.split(":")[1]
        cottura = details[2].text.split(":")[1]
        dosi_per = details[3].text.split(":")[1]
        costo = details[4].text.split(":")[1]
    except Exception as e:
        print(e)
        pass
    dettagli.append({'id_a': id_a, 'rate' : rate, 'n_voti': n_voti, 'n_commenti' : n_commenti, 'difficolta': difficolta, 'preparazione': preparazione, 'dosi_per': dosi_per, 'costo': costo})
 
 # ## ingredienti 
 
 lista_ingredienti = []

for item in tqdm(ds_antipasti.iterrows(), total=ds_antipasti.shape[0]):
    try:
        id_a = item[1][3]
        link = item[1][1]
        resp = requests.get(link, verify = False)
        parse = bs4.BeautifulSoup(resp.text)
        ingr = parse.select('dd', class_= 'dz-ingredients')
        n_ingredienti = len(ingr)
        ingredienti = list(map(lambda x: ' '.join(x.text.split()), ingr))
    except Exception as e:
        print(e)
        pass
    lista_ingredienti.append({'id_a': id_a, 'n_ingredienti': n_ingredienti, 'ingredienti': ingredienti})
 
 # creazione dataframe
import pandas as pd
ds_dettagli = pd.DataFrame(dettagli)
ds_dettagli.head()


ds_ingredienti = pd.DataFrame(lista_ingredienti)
ds_ingredienti.head()

# merge dei due dataframe 

lista_dettagli = pd.DataFrame.merge(ds_dettagli, ds_ingredienti, on='id_a', how='left')

# step preparazione e link foto 

for i in range(0, len(img)):
    try:
        s = parse.findAll('div', class_='gz-content-recipe-step')[i].text.replace('\n', "")
        print('{}{}'.format(s,i))
        img = 'https://ricette.giallozafferano.it/'+ parse.find_all('div', class_='gz-content-recipe-step')[i].find("source")["data-srcset"]
        print('{}{}'.format(img,i))
    except:
        pass






