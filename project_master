

# ## - Importiamo le librerie che servono per fare Web Scraping da tripadvisor.com

import requests 
import bs4
import csv
from tqdm import tqdm_notebook as tqdm
import pprint


num = 1
webpage = f"https://www.giallozafferano.it/ricette-cat/page{num}/Antipasti/"
response = requests.get(webpage, verify=False)
print("Status: " + str(response.status_code))


doc = bs4.BeautifulSoup(response.text)

# ## First page 

# ### Tutte le ricette della prima pagina


lista = doc.find_all('div', class_ = "gz-content-recipe-horizontal")
titolo = doc.find('h2', class_ = "gz-title")

link = doc.find('h2', class_ = "gz-title").find("a")["href"]

descrizione =  doc.find('div', class_ = "gz-description").text

antipasti_list = []
for antipasto in lista :
    titolo = antipasto.find('h2', class_ = "gz-title").text
    link = antipasto.find('h2', class_ = "gz-title").find("a")["href"]
    descrizione =  antipasto.find('div', class_ = "gz-description").text
    antipasti_list.append({'titolo' : titolo, 'link' : link, 'descrizione' : descrizione})



def parse_antipasti(antipasto):
    titolo = antipasto.find('h2', class_ = "gz-title").text
    link = antipasto.find('h2', class_ = "gz-title").find("a")["href"]
    descrizione =  antipasto.find('div', class_ = "gz-description").text
    return {'titolo' : titolo, 'link' : link, 'descrizione' : descrizione}


antipasti_list= []
for num in tqdm(range(1,11)):
    webpage = f"https://www.giallozafferano.it/ricette-cat/page{num}/Antipasti/"
    response = requests.get(webpage,  verify=False)
    doc = bs4.BeautifulSoup(response.text)
    lista = doc.select('div', class_ = "gz-content-recipe-horizontal")
    for antipasto in lista:
        try:
            antipasti_list.append(parse_antipasti(antipasto))
        except:
            pass

print(len(antipasti_list))

# creazione dataframe
import pandas as pd

ds_antipasti = pd.DataFrame(antipasti_list)
ds_antipasti.head(20)

# creazione csv

ds_antipasti.info()
ds_antipasti.to_csv("/home/master/antipasti.csv")


# ## Per ogni link

page = f'https://ricette.giallozafferano.it/Polpettine-di-tonno-e-ricotta.html'
print(page)

resp = requests.get(page, verify = False)
parse = bs4.BeautifulSoup(resp.text)

dettagli = parse.find_all('span', class_ = 'gz-name-featured-data')

difficolta = dettagli[0].text.split(":")[1]

preparazione = dettagli[1].text.split(":")[1]

cottura = dettagli[2].text.split(":")[1]

dosi_per = dettagli[3].text.split(":")[1]

costo = dettagli[4].text.split(":")[1]

ingredienti = parse.select('dd', class_= 'dz-ingredients')
len(ingredienti)


# ## Lista ingredienti per ricetta

for i in range(0, len(ingredienti)):
               s = (ingredienti[i].text.split())
               print(" ".join(s))

n_voti = parse.find('div', class_="rating_rate")["title"]
print(n_voti)
n_commenti = parse.find('div', class_='gz-pTop4x').text.replace("\n","")
print(n_commenti)


